{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "try:\n",
    "    os.chdir(os.path.join(os.getcwd(), 'c:\\\\Users\\\\602870\\\\Desktop\\\\gamechanger\\\\gamechanger')) # '.' if the path is to current folder\n",
    "except:\n",
    "    pass\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import spacy as sp\n",
    "import time\n",
    "\n",
    "# from dataScience.src.utilities.text_utils import simple_clean\n",
    "import dataScience.src.utilities.spacy_model as spacy_\n",
    "from dataScience.src.utilities.text_utils import simple_clean\n",
    "from dataScience.src.featurization.extract_improvement.extract_utils import extract_entities, create_list_from_dict, remove_articles, match_parenthesis\n",
    "\n",
    "spacy_model = spacy_.get_lg_nlp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = ['USD(C CFO', 'DoDD', 'DeCA', 'Department of Defense', 'CFO', 'Defense (Comptroller Chief Financial Officer', 'Defense for Policy (']\n",
    "# match_parenthesis(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Manage and conduct DIAâ€™s worldwide Defense HUMINT collection operations in support of DoD and IC requirements, provide direct access to critical military information, and enable other intelligence collection disciplines in accordance with DoD Directives S-5105.29 and 5200.37 (References (r) and (s)).\n"
     ]
    }
   ],
   "source": [
    "test = 'Manage and conduct DIA\\u2019s worldwide Defense HUMINT collection operations in \\nsupport of DoD and IC requirements, provide direct access to critical military information, and \\nenable other intelligence collection disciplines in accordance with DoD Directives S-5105.29 and \\n5200.37 (References (r) and (s)).'\n",
    "test = re.sub(\"[\\\\n\\\\t\\\\r]+\", \"\", test)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"ref\"] = \"\"\n",
    "for i, row in df.iterrows():\n",
    "    for j in list(df.columns):\n",
    "        if isinstance(row[j],str):\n",
    "            if \":\" in row[j]:\n",
    "                if \"shall\" in row[j]:\n",
    "                    entity = row[j].split(\":\",1)[0]\n",
    "                    entity = entity.split(\"shall\",1)[0]\n",
    "                    entity = entity.split(\".\")[-1].strip()\n",
    "\n",
    "                    df.at[i,'entity'] = entity\n",
    "\n",
    "    agencies = []\n",
    "    refs = []\n",
    "    for j in list(df.columns):\n",
    "\n",
    "        if type(row[j]) == str:\n",
    "            if j!= \"doc\":\n",
    "                refs.append(list(collect_ref_list(row[j]).keys()))\n",
    "                agencies.append([aliases[x] for x in aliases.keys() if \" \"+str(x) in row[j]])\n",
    "    flat_a = [item for sublist in agencies for item in sublist]\n",
    "    flat_a = set(flat_a)\n",
    "    df.at[i,'agencies'] = list(flat_a)\n",
    "    flat_r = [item for sublist in refs for item in sublist]\n",
    "    flat_r = list(set(flat_r))\n",
    "    df.at[i,'ref'] = flat_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('dataScience/src/featurization/extract_improvement/data/pipe.csv')\n",
    "data['agencies'].replace(np.nan, '', regex=True, inplace=True)\n",
    "combined_cols = pd.DataFrame(data[data.columns[1:]].apply(lambda x: ','.join(x.dropna().astype(str)), axis=1), columns=['text'])\n",
    "combined_cols_list = combined_cols['text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Record number:  0 0.05 seconds\n",
      "Record number:  200 16.64 seconds\n",
      "Record number:  400 25.5 seconds\n",
      "Record number:  600 32.08 seconds\n",
      "Record number:  800 42.68 seconds\n",
      "Record number:  1000 54.38 seconds\n",
      "Record number:  1200 67.41 seconds\n",
      "Record number:  1400 74.24 seconds\n",
      "Record number:  1600 79.06 seconds\n",
      "Record number:  1800 83.55 seconds\n",
      "Record number:  2000 87.78 seconds\n",
      "Record number:  2200 93.81 seconds\n",
      "Record number:  2400 98.05 seconds\n",
      "Record number:  2600 103.8 seconds\n",
      "Record number:  2800 108.27 seconds\n",
      "Record number:  3000 112.7 seconds\n",
      "\n",
      "Elapsed seconds: 114.97195935249329\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "per_doc_list = []\n",
    "all_docs = []\n",
    "\n",
    "for i in range(len(combined_cols_list)):\n",
    "    sentence = combined_cols_list[i]\n",
    "    entities = extract_entities(sentence, spacy_model)\n",
    "    \n",
    "    # if i % 200 == 0:\n",
    "    #     print('Record number: ', i, round(time.time() - start, 2), 'seconds')\n",
    "\n",
    "    #TODO replace when integrating into responsibilties pipeline\n",
    "    prev_agencies = [x.strip() for x in data['agencies'][i].split(',')]\n",
    "    prev_agencies = [i for i in prev_agencies if i]\n",
    "    \n",
    "    flat_entities = create_list_from_dict(entities)\n",
    "    for j in prev_agencies:\n",
    "        flat_entities.append(j)\n",
    "    \n",
    "    flat_entities = remove_articles(flat_entities)\n",
    "    flat_entities = match_parenthesis(flat_entities)\n",
    "    flat_entities = '|'.join(i for i in set(flat_entities))\n",
    "    all_docs.append(flat_entities)\n",
    "\n",
    "data['agencies'] = all_docs\n",
    "data.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "print()\n",
    "print('Elapsed seconds:', time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.loc[data['doc'] == 'DODD 1000.21E CH 2.json']\n",
    "data.to_csv('dataScience/src/featurization/extract_improvement/model_outputs/full_pipe_w_new_entities_030221.csv')"
   ]
  }
 ]
}